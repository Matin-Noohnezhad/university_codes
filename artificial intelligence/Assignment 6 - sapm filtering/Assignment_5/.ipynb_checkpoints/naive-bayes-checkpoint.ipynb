{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part1 :Naive Bayes\n",
    "\n",
    "In this exercise you will be writing a spam detector with Naive Bayes. Download emails.zip  below. This dataset consists of four sets of data: nonspam-test, spam-test, nonspam-train, and spam-train. You should use the training emails to build a Naive Bayes model, and the testing emails to test the accuracy of your model. What percentage of emails in nonspam-test does your model predict to be non-spam, and what percentage of emails in spam-test does your model predict to be spam? (these two numbers tell the accuracy of your model).\n",
    "1. Represent each email by a set of unique words (use set in python). \n",
    "2. Exclude default English stop words from each email (If A and B are python sets you can exclude members of B from A by subtraction: A-B). \n",
    "3. Create two dictionaries nonspam_counts and spam_counts. These two dictionaries keep counts of each word in spam and nonspam emails. Initially for any possible word in the training data do:\n",
    "    nonspam_counts[word] = alpha \n",
    "    spam_counts[word] = alpha \n",
    "where alpha is a number very close to zero (you can initially set alpha to 0.001). \n",
    "4. For each word in each email of the training data update the counts in  spam_counts and nonspam_counts. (Note that since each email is considered a set, if a word happened a couple of times it is counted only once)\n",
    "5. Define a function called classify. This function takes an email and classify the email as spam or no spam. To avoid dealing with underflow use logs and additions in place of multiplication. For example instead of a*b use log(a)+log(b).  \n",
    "Note that \n",
    "P(spam|email) = P(email|spam)*P(spam)/P(email)\n",
    "therefore \n",
    "log(P(spam|email) = log(P(email|spam)) + log(P(spam)) - log(P(email))\n",
    "similarly \n",
    "log(P(nonspam|email) = log(P(email|nonspam)) + log(P(nonspam)) - log(P(email))\n",
    "On the other hand you should classify the email as spam if \n",
    "P(spam|email) > P(nonspam|email) \n",
    "or equivalently if \n",
    "log(P(spam|email) > log(P(nonspam|email) \n",
    "or equivalently if \n",
    "log(P(email|spam)) + log(P(spam)) - log(P(email)) > log(P(email|nonspam)) + log(P(nonspam)) - log(P(email)) \n",
    "or equivalently if \n",
    "log(P(email|spam)) + log(P(spam)) > log(P(email|nonspam)) + log(P(nonspam))\n",
    "6. Compute the accuracy of the model by calling classify on the test data (what percentage of your calls return the right answer).\n",
    "7. Now change alpha (make it smaller) , does the accuracy change? try it with a couple of different alphas, what is the best accuracy. \n",
    "8 (Optional). Install and use nltk package for lemmatization and stemming. Lemmatization and stemming should improve your model's accuracy. \n",
    "____\n",
    "Theoretical questions \n",
    "1. Let X be a random variable for coin that comes up heads with probability φ, i.e. X ~ Bernoulli(φ) or P(X=1) = φ. Furthermore assume there is a prior on φ that follows a Gaussian distribution with mean μ and variance σ, i.e. φ ~ N(μ, σ). We flip the coin n times and observe m heads and n-m tails. What is the posterior of X, i.e. P(φ| X1, X2, ..., Xn)? Assume that X1, X2, ..., Xn all follow Bernoulli distributions and are iid.\n",
    "2. Prove that if x|y=0 ~ N(μ0, Σ) and x|y=1 ~ N(μ1, Σ) and y ~ Bernoulli(φ) then P(y=1|x) = 1/1+e{-w.x} for a w.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from os.path import isfile, join\n",
    "\n",
    "stop_words = set([\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\tourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"])\n",
    "\n",
    "def get_data(path):\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    def get_words(f):\n",
    "        result = []\n",
    "        for line in open(path+'/'+f, 'rb'):\n",
    "            for word in line.strip().split():\n",
    "                result.append(word)\n",
    "        return set(result) - stop_words\n",
    "    return [get_words(file) for file in files]\n",
    "\n",
    "\n",
    "test_nonspam =get_data('./emails/nonspam-test')\n",
    "train_nonspam =get_data('./emails/nonspam-train')\n",
    "test_spam =get_data('./emails/spam-test')\n",
    "train_spam =get_data('./emails/spam-train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spam_vocab = set.union(*train_spam)\n",
    "non_spam_vocab = set.union(*train_nonspam)\n",
    "vocab = list ( spam_vocab.union(non_spam_vocab) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = 0.0001\n",
    "spam_counts = {}\n",
    "nonspam_counts = {}\n",
    "\n",
    "\n",
    "for word in possible_words:\n",
    "    spam_counts[word] = alpha\n",
    "    nonspam_counts[word] = alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
